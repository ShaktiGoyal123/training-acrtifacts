{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests\n",
    "pip install html5lib\n",
    "pip install bs4\n",
    "#pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "\n",
    "# For web scraping\n",
    "import requests\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# For performing regex operations\n",
    "import re\n",
    "\n",
    "# Data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the URL of the webpage we want to scrape to a variable\n",
    "url = 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2021/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import requests \n",
    "#from bs4 import BeautifulSoup\n",
    "\n",
    "response = requests.get(url) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the undecoded content into a Beautiful Soup object and assign it to a variable\n",
    "try:\n",
    "    soup = BeautifulSoup(response.content, 'html5lib') # If this line causes an error, run 'pip install html5lib' or install html5lib \n",
    "    print(soup.prettify())\n",
    "except Exception as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "\n",
    "weathers=[]  # a list to store weather data \n",
    "   \n",
    "table = soup.find('div', attrs = {'id':'all_weather'}) \n",
    "\n",
    "for row in table.findAll('div', \n",
    "                         attrs = {'class':'col-6 col-lg-3 text-center margin-30px-bottom sm-margin-30px-top'}): \n",
    "    weather = {} \n",
    "    weather['theme'] = row.h5.text \n",
    "    weather['url'] = row.a['href'] \n",
    "    weather['img'] = row.img['src'] \n",
    "    weather['lines'] = row.img['alt'].split(\" #\")[0] \n",
    "    weather['author'] = row.img['alt'].split(\" #\")[1] \n",
    "    weathers.append(weather) \n",
    "   \n",
    "filename = 'weather_data.csv'\n",
    "with open(filename, 'w', newline='') as f: \n",
    "    w = csv.DictWriter(f,['theme','url','img','lines','author']) \n",
    "    w.writeheader() \n",
    "    for weather in weathers: \n",
    "        w.writerow(weather) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
